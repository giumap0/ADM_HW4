{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from heapq import heappush, nlargest\n",
    "\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "# First way\n",
    "#TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "#IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "\n",
    "def calculate_tf_idf(airbnb_data,inverted_idx,vocabulary):\n",
    "    \"\"\"\n",
    "    method that computes an inverted index\n",
    "    \n",
    "    input:  airbnbdata-just for using the number of files we made\n",
    "            inverted_idx(dictionary, key=term_id, value=list of document_ids)\n",
    "            vocabulary(dictionary of all unique words, key=term, value=term_id)\n",
    "    output: tf_idf_dic(dictionary of tf_idf_values for all docs, key=tuple(term,doc_id ), value=tf_idf value)\n",
    "    \"\"\"\n",
    "    tf_idf_dic=dict()\n",
    "    #number of .tsv files which were made\n",
    "    total_num_docs=airbnb_data.shape[0]\n",
    "    result_df=pd.DataFrame()\n",
    "    for i in airbnb_data.index:\n",
    "        #take one file\n",
    "        df=pd.read_csv('data/doc_'+str(i)+'.tsv',sep='\\t',usecols=['description','title'],encoding='ISO-8859-1')\n",
    "        #preprocessing \n",
    "        df=df.description[0]+' '+df.title[0] \n",
    "        filtered_words=preprocessing_text(df)\n",
    "        tf_series=pd.Series(filtered_words)\n",
    "        #series of tf values\n",
    "        tf_series=((tf_series.value_counts())/len(tf_series)).sort_index()\n",
    "        idf_series=pd.Series(list(set(filtered_words))).sort_values()\n",
    "        #idf calculation\n",
    "        idf_calc=idf_series.apply(lambda x: np.log(total_num_docs/len(inverted_idx[vocabulary[x]])))\n",
    "        #combine tf and idf in one result_df dataframe\n",
    "        result_df=pd.concat([pd.Series(idf_series.values),pd.Series(tf_series.values),pd.Series(idf_calc.values)],axis=1)#.reset_index()\n",
    "        #multiply tf and idf and create tf_idf column\n",
    "        result_df['tf_idf']=result_df[1]*result_df[2]\n",
    "        #key=tuple(term,doc_id), value=tf_idf value\n",
    "        for idx in range(result_df.shape[0]):\n",
    "            tf_idf_dic[result_df[0][idx],i]=result_df['tf_idf'][idx]\n",
    "    return tf_idf_dic        \n",
    "\n",
    "# Second way--to check if it is the same like the 1st-for double checking the results\n",
    "def calculate_tf_idf2(airbnb_data,inverted_idx,vocabulary):\n",
    "    \"\"\"\n",
    "    method that computes an inverted index(stores it differently than the first one just for comparison)\n",
    "    \n",
    "    input:  airbnbdata-just for using the number of files we made\n",
    "            inverted_idx(dictionary, key=term_id, value=list of document_ids)\n",
    "            vocabulary(dictionary of all unique words, key=term, value=term_id)\n",
    "    output: proba(dictionary of tf_idf_values for all docs)\n",
    "    \"\"\"\n",
    "    #store separately tf and idf values into dictionaries\n",
    "    idf_dic2={}\n",
    "    tf_dic2={}\n",
    "    #dictionary for tf_idf values\n",
    "    proba={}\n",
    "    total_num_docs=airbnb_data.shape[0]\n",
    "\n",
    "    for i in airbnb_data.index:\n",
    "        #take one file\n",
    "        df=pd.read_csv('data/doc_'+str(i)+'.tsv',sep='\\t',usecols=['description','title'],encoding='ISO-8859-1')\n",
    "        #preprocessing \n",
    "        df=df.description[0]+' '+df.title[0] \n",
    "        #preprocessed words\n",
    "        filtered_words=preprocessing_text(df)\n",
    "        #tf values calculations\n",
    "        tf_series=pd.Series(filtered_words)\n",
    "        tf_series=((tf_series.value_counts())/len(tf_series)).sort_index()\n",
    "        #idf values calculations\n",
    "        idf_series=pd.Series(list(set(filtered_words))).sort_values()\n",
    "        idf_calc=idf_series.apply(lambda x: np.log(total_num_docs/len(inverted_idx[vocabulary[x]])))\n",
    "        #store idf values into dict\n",
    "        for idx in range(len(tf_series)):\n",
    "            idf_dic2[idf_series[idx],i]=idf_calc[idx] \n",
    "        #store tf values into dict\n",
    "        for index,value in tf_series.iteritems():\n",
    "            tf_dic2[index,i]=value\n",
    "        #combine tf and idf ito a new dictionary by their multiplication using the same key\n",
    "        for k in tf_dic2.keys():\n",
    "            proba[k]=tf_dic2[k]*idf_dic2[k]\n",
    "    return proba        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
